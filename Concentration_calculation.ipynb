{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CodingTask1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TillVollmer5/mass_spectroscopy/blob/main/Concentration_calculation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Concentration calculation\n",
        "This notebook is used to calculate the concentration of phtalates in an environemental sample using an internal standard for quantitation. The Calibration_calculation.ipynb notebook, yields severall of the required files nescessary for the calculations in this notebook. The files *Cal_{n}_analyte_linreg.csv* need to be used which is located in the *calibration_output* folder on the google drive. If this notebook is not applied from my machine in connection with my google drive, either the path to the required files needs to be adabted or changed.\n",
        "The following code allows for the calculation of the concentration, by using the linear regression form a calibration series and the ratio of the signal of the analyte with the internal standard (area). All the data regarding the calibration are present on my google drive in the folders: *calibration_input* and *calibration_output*, while a new google drive folder will be used to save the final data in as well as a new input folder.\n",
        "\n",
        "*Google drive folder:*\n",
        "quantitation_input\n",
        "quantitation_output\n",
        "\n",
        "The .csv files containing the peak list from the sample should be saved in the in the input folder. The names should follow a consequent naming sceme:\n",
        "\n",
        "***Sample_{date_of_analysis}_{tag_bonus_info}_{Sample_Nr}_pl.csv***\n",
        "\n",
        "Here the Sample number *(Sample_Nr)* is of key importance and needs to be properly documented in the Labjournal, as it is the main way of differentiation.\n"
      ],
      "metadata": {
        "id": "HlXOz_s2lyh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code is used to import all the nescessary libraries and mount the google drive."
      ],
      "metadata": {
        "id": "nPldWo5uaB-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import glob\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "\n",
        "sample_nr_low = 1 #needs to be addapted to 1 nr in the series\n",
        "sample_nr_high = 2 #needs to be addapted to the last nr of the series"
      ],
      "metadata": {
        "id": "f0Rraq8-lx2k",
        "outputId": "6c3dd8e3-a3a5-4252-9855-86cac129aa54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code is the addapted code from the Calibration_calculation.ipynb and yields the separated in separated .csv files, which will be used to calculate the ratio in a following code segment.\n",
        "\n",
        "The output file has the following filename and is saved in the quantitation_output folder:\n",
        "\n",
        "***Sample_{n}_row{i+1}.csv***"
      ],
      "metadata": {
        "id": "iRIOk4_na2v0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loop over all the designated sample files.\n",
        "for n in range(sample_nr_low, sample_nr_high):\n",
        "    files = glob.glob(f'/content/drive/My Drive/quantitation_input/*_{n}_pl.csv')\n",
        "\n",
        "    if not files:\n",
        "        print(f'Files matching pattern Sample Nr. {n} was not found.')\n",
        "        break\n",
        "\n",
        "    else:\n",
        "        # Loop over each row and save a separate data frame for each\n",
        "        df = pd.read_csv(files[0], header=4)\n",
        "        num_rows = len(df)\n",
        "        \n",
        "        for i in range(num_rows):\n",
        "            row_dfs = []\n",
        "            for file in files:\n",
        "                df = pd.read_csv(file, header=4, na_values='')\n",
        "\n",
        "                # Extract the i'th row of the CSV file and append it to the row data frame list\n",
        "                row = df.iloc[i, :].dropna().astype(str)\n",
        "                row_dfs.append(row)\n",
        "\n",
        "            # Concatenate the row data frames along the columns axis and convert to a data frame\n",
        "            combined_df = pd.concat(row_dfs, axis=1).T\n",
        "\n",
        "            # Save the combined data frame to a CSV file with a name indicating the row number\n",
        "            combined_df.to_csv(f'/content/drive/My Drive/quantitation_output/Sample_{n}_row{i+1}.csv', index=False, header=False)\n",
        "            \n",
        "            # Convert all values to strings before joining and print the row in the desired format\n",
        "            formatted_row = '\\t'.join(map(str, combined_df.values[0]))\n",
        "            print(formatted_row)"
      ],
      "metadata": {
        "id": "wtrzzQvHa2TP",
        "outputId": "681e2e5f-2b8e-430f-f1e0-4a3979f7c9f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14.7\t14.64\t14.76\t8899641679.645\t22.39\t4269043599.688\t22.58\n",
            "17.48\t17.43\t17.53\t11726497950.556\t29.51\t5937387109.376\t31.4\n",
            "20.79\t20.73\t20.86\t12856490362.673\t32.35\t6025451308.624\t31.87\n",
            "23.92\t23.88\t24.0\t4783695940.843\t12.04\t2205044360.583\t11.66\n",
            "29.63\t29.57\t29.81\t1153167025.723\t2.9\t368569331.242\t1.95\n",
            "32.17\t32.13\t32.34\t198929696.131\t0.5\t64452863.573\t0.34\n",
            "34.55\t34.5\t34.7\t121997454.463\t0.31\t38422419.591\t0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code allows to calculate the ratio of the analytes with the internal standard. The output is saved as:\n",
        "\n",
        "***Sample_{n}_row*_ratio.csv**"
      ],
      "metadata": {
        "id": "4P-AJhGWfCXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loop over all the designated sample files.\n",
        "for n in range(sample_nr_low, sample_nr_high):\n",
        "  divisor_file = f'/content/drive/My Drive/quantitation_output/Sample_{n}_row3.csv'\n",
        "  directory = '/content/drive/My Drive/quantitation_output'\n",
        "    \n",
        "  divisor_row = pd.read_csv(divisor_file, sep=',', header=None)\n",
        "  #print(divisor_row)\n",
        "  csv_files = glob.glob(os.path.join(directory, f'*_row*.csv'))\n",
        "\n",
        "    \n",
        "  # Process each CSV file\n",
        "  for csv_file in csv_files:\n",
        "    if csv_file == divisor_file:\n",
        "      continue  # Skip the divisor file itself\n",
        "\n",
        "    data_df = pd.read_csv(csv_file, sep=',', header=None)\n",
        "    #print(data_df)\n",
        "    data_df = data_df.apply(pd.to_numeric, errors='coerce')  # Convert values to numeric\n",
        "      \n",
        "    # Perform division on the data\n",
        "    divided_data_df = data_df.div(divisor_row, axis='columns')\n",
        "    #print(divided_data_df)\n",
        "    #Create a new file name with the \"_ratio\" tag\n",
        "    new_file_name = os.path.splitext(csv_file)[0] + '_ratio.csv'\n",
        "\n",
        "    divided_data_df.to_csv(new_file_name, sep='\\t', header=False, index=False)\n",
        "    print(new_file_name)"
      ],
      "metadata": {
        "id": "oXCb2CjmfhuM",
        "outputId": "8b659fa5-62f5-49b1-c351-4a99f9d0c87c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/quantitation_output/Sample_1_row1_ratio.csv\n",
            "/content/drive/My Drive/quantitation_output/Sample_1_row2_ratio.csv\n",
            "/content/drive/My Drive/quantitation_output/Sample_1_row4_ratio.csv\n",
            "/content/drive/My Drive/quantitation_output/Sample_1_row5_ratio.csv\n",
            "/content/drive/My Drive/quantitation_output/Sample_1_row6_ratio.csv\n",
            "/content/drive/My Drive/quantitation_output/Sample_1_row7_ratio.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code takes the ratio files as well as the parameters for the linear regression (analyte specific), and yields a final output file that contains all the information, such as the information of the ratio used for the quantitaiton, the parameters for the linear equation as well as other information such as compound id and other general sample information. \n",
        "\n",
        "The final outpur files have the following name format:\n",
        "\n",
        "***Sample_{n}_quantitation_output.csv***\n"
      ],
      "metadata": {
        "id": "8b_QdJRpho9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_pattern = '/content/drive/My Drive/quantitation_output/Sample_{}_row{}_ratio.csv'\n",
        "linregs = {}\n",
        "\n",
        "for i in range(1, 7):\n",
        "    if i == 3:\n",
        "        continue\n",
        "    linreg = glob.glob(f'/content/drive/My Drive/calibration_export/Cal_{i}_analyte_linreg.csv')\n",
        "    if len(linreg) > 0:\n",
        "        linregs[i] = pd.read_csv(linreg[0])\n",
        "    else:\n",
        "        print(f\"No matching file found for Cal_{i}_analyte_linreg.csv\")\n",
        "\n",
        "print(linregs)\n",
        "\n",
        "output_dir = '/content/drive/My Drive/quantitation_output/'\n",
        "header_row1 = ['Header1', 'Header2', 'Header3', 'Header4']\n",
        "header_row2 = ['Descriptor', 'Intercept', 'Slope', 'Value', 'Concentration']\n",
        "\n",
        "row_descriptors = ['Row A', 'Row B', 'Row C', 'Row D', 'Row E', 'Row F']\n",
        "\n",
        "for n in range(sample_nr_low, sample_nr_high):\n",
        "    output_file = output_dir + f'Sample_{n}_concentration_output.csv'\n",
        "\n",
        "    with open(output_file, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(header_row1)\n",
        "        writer.writerow(header_row2)\n",
        "\n",
        "        for i, descriptor in enumerate(row_descriptors):\n",
        "            files = glob.glob(file_pattern.format(n, i+1))\n",
        "            for file in files:\n",
        "                sample_df = pd.read_csv(file, header=None)\n",
        "                if sample_df.shape[0] >= 1:\n",
        "                    linreg_df = linregs.get(i + 1)\n",
        "                    if linreg_df is not None and linreg_df.shape[0] >= 1:\n",
        "                        intercept_str = linreg_df['Intercept'].values[0]\n",
        "                        slope_str = linreg_df['Slope'].values[0]\n",
        "\n",
        "                        if intercept_str and slope_str:\n",
        "                            intercept = float(re.findall(r'[-\\d.]+', intercept_str)[0])\n",
        "                            slope = float(re.findall(r'[-\\d.]+', slope_str)[0])\n",
        "\n",
        "                            values = sample_df.iloc[0, 0].split('\\t')\n",
        "                            value = float(values[0])\n",
        "                            concentration = slope * value + intercept\n",
        "\n",
        "                            row_data = [descriptor, intercept, slope, value, concentration]\n",
        "                            writer.writerow(row_data)\n",
        "                        else:\n",
        "                            print(f\"Invalid linreg DataFrame structure for {file}\")\n",
        "                    else:\n",
        "                        print(f\"Invalid linreg DataFrame structure for {file}\")\n",
        "                else:\n",
        "                    print(f\"Empty or invalid sample DataFrame for {file}\")\n"
      ],
      "metadata": {
        "id": "PUgcC3a8p5hi",
        "outputId": "ae5a145b-c897-4435-a40a-7293955fce9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1:        Intercept           Slope  R2 Value\n",
            "0  [-0.02459418]  [[0.20015848]]   0.98714, 2:        Intercept           Slope  R2 Value\n",
            "0  [-0.03101178]  [[0.26080997]]  0.988923, 4:        Intercept           Slope  R2 Value\n",
            "0  [-0.04441677]  [[0.34518071]]  0.988097, 5:        Intercept           Slope  R2 Value\n",
            "0  [-0.03514634]  [[0.19182459]]  0.976946, 6:        Intercept           Slope  R2 Value\n",
            "0  [-0.04753296]  [[0.24848578]]  0.975333}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ix6erLGQvWH8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}