{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CodingTask1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TillVollmer5/mass_spectroscopy/blob/main/Concentration_calculation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Concentration calculation\n",
        "This notebook is used to calculate the concentration of phtalates in an environemental sample using an internal standard for quantitation. The Calibration_calculation.ipynb notebook, yields severall of the required files nescessary for the calculations in this notebook. The files *Cal_{n}_analyte_linreg.csv* need to be used which is located in the *calibration_output* folder on the google drive. If this notebook is not applied from my machine in connection with my google drive, either the path to the required files needs to be adabted or changed.\n",
        "The following code allows for the calculation of the concentration, by using the linear regression form a calibration series and the ratio of the signal of the analyte with the internal standard (area). All the data regarding the calibration are present on my google drive in the folders: *calibration_input* and *calibration_output*, while a new google drive folder will be used to save the final data in as well as a new input folder.\n",
        "\n",
        "*Google drive folder:*\n",
        "quantitation_input\n",
        "quantitation_output\n",
        "\n",
        "The .csv files containing the peak list from the sample should be saved in the in the input folder. The names should follow a consequent naming sceme:\n",
        "\n",
        "***Sample_{date_of_analysis}_{tag_bonus_info}_{Sample_Nr}_pl.csv***\n",
        "\n",
        "Here the Sample number *(Sample_Nr)* is of key importance and needs to be properly documented in the Labjournal, as it is the main way of differentiation.\n"
      ],
      "metadata": {
        "id": "HlXOz_s2lyh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code is used to import all the nescessary libraries and mount the google drive."
      ],
      "metadata": {
        "id": "nPldWo5uaB-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import glob\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "from datetime import datetime\n",
        "import re\n",
        "import ast\n",
        "\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "\n",
        "sample_nr_low = 177 #needs to be adapted to 1 nr in the series\n",
        "sample_nr_high = 178 #needs to be adapted to the last nr of the series"
      ],
      "metadata": {
        "id": "f0Rraq8-lx2k",
        "outputId": "9ac9a983-6aba-43f4-c79a-206e7d607e07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code is the addapted code from the Calibration_calculation.ipynb and yields the separated in separated .csv files, which will be used to calculate the ratio in a following code segment.\n",
        "\n",
        "The output file has the following filename and is saved in the quantitation_output folder:\n",
        "\n",
        "***Sample_{n}_row{i+1}.csv***"
      ],
      "metadata": {
        "id": "iRIOk4_na2v0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loop over all the designated sample files.\n",
        "for n in range(sample_nr_low, sample_nr_high):\n",
        "    files = glob.glob(f'/content/drive/My Drive/quantitation_input/*_{n}_pl.csv')\n",
        "\n",
        "    if not files:\n",
        "        print(f'Files matching pattern Sample Nr. {n} was not found.')\n",
        "        continue\n",
        "\n",
        "    else:\n",
        "        # Loop over each row and save a separate data frame for each\n",
        "        df = pd.read_csv(files[0], header=4)\n",
        "        num_rows = len(df)\n",
        "\n",
        "        for i in range(num_rows):\n",
        "            row_dfs = []\n",
        "            for file in files:\n",
        "                df = pd.read_csv(file, header=4, na_values='')\n",
        "\n",
        "                # Extract the i'th row of the CSV file and append it to the row data frame list\n",
        "                row = df.iloc[i, :].dropna().astype(str)\n",
        "                row_dfs.append(row)\n",
        "\n",
        "            # Concatenate the row data frames along the columns axis and convert to a data frame\n",
        "            combined_df = pd.concat(row_dfs, axis=1).T\n",
        "\n",
        "            # Save the combined data frame to a CSV file with a name indicating the row number\n",
        "            combined_df.to_csv(f'/content/drive/My Drive/quantitation_output/Sample_{n}_row{i+1}.csv', index=False, header=False)\n",
        "\n",
        "            # Convert all values to strings before joining and print the row in the desired format\n",
        "            formatted_row = '\\t'.join(map(str, combined_df.values[0]))\n",
        "            print(formatted_row)"
      ],
      "metadata": {
        "id": "wtrzzQvHa2TP",
        "outputId": "a6c9c6ab-5e93-466d-8c5f-b7326bc3b8e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13.8\t13.75\t13.86\t1480879.721\t100.0\t661382.63\t100.0\n",
            "15.74\t15.67\t15.82\t49894536.345\t29.99\t22338694.843\t30.75\n",
            "18.59\t18.54\t18.64\t745155459.332\t100.0\t344343165.51\t100.0\n",
            "20.6\t20.56\t20.65\t22458149.848\t13.5\t9741519.653\t13.41\n",
            "25.62\t25.6\t25.62\t974144.385\t0.59\t778397.485\t1.07\n",
            "26.75\t26.7\t26.84\t92557585.3\t55.63\t39003557.982\t53.69\n",
            "29.28\t29.28\t29.3\t509975.95\t0.31\t780206.637\t1.07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code allows to calculate the ratio of the analytes with the internal standard. The output is saved as:\n",
        "\n",
        "***Sample_{n}_row*_ratio.csv**"
      ],
      "metadata": {
        "id": "4P-AJhGWfCXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop over all the designated sample files. Currently works but i am not sure if it might be just exactly the same as the first one, it works but not iterative...\n",
        "for n in range(sample_nr_low, sample_nr_high):\n",
        "    divisor_file = f'/content/drive/My Drive/quantitation_output/Sample_{n}_row3.csv'\n",
        "    directory = '/content/drive/My Drive/quantitation_output'\n",
        "\n",
        "    if not os.path.isfile(divisor_file):\n",
        "        print(f\"Divisor file does not exist: {divisor_file}\")\n",
        "        continue  # Skip to the next iteration if the divisor file is missing\n",
        "\n",
        "    divisor_df = pd.read_csv(divisor_file, sep=',', header=None)\n",
        "    csv_files = glob.glob(os.path.join(directory, f'*{n}_row*.csv'))\n",
        "\n",
        "    # Process each CSV file\n",
        "    for csv_file in csv_files:\n",
        "        if csv_file == divisor_file or '_ratio' in csv_file:\n",
        "            continue  # Skip the divisor file itself and ratio files\n",
        "        data_df = pd.read_csv(csv_file, sep=',', header=None)\n",
        "        data_df = data_df.apply(pd.to_numeric, errors='coerce')  # Convert values to numeric\n",
        "        print('divisor_df:', divisor_df)\n",
        "        print('data_df:', data_df)\n",
        "        divided_data_df = pd.DataFrame()\n",
        "\n",
        "        for i in range(len(data_df)):\n",
        "          # Perform division on the data on the complete dataframe\n",
        "          divided_row = data_df.iloc[i] / divisor_df.iloc[i]\n",
        "          divided_data_df = divided_data_df.append(divided_row, ignore_index=True)\n",
        "\n",
        "        # Create a new file name with the \"_ratio\" tag\n",
        "        new_file_name = os.path.splitext(csv_file)[0] + '_ratio.csv'\n",
        "\n",
        "        divided_data_df.to_csv(new_file_name, sep=',', header=False, index=False)\n",
        "        control_import_df = pd.read_csv(new_file_name, sep=',', header=None)\n",
        "\n",
        "        # Compare the recalculated values with the content of the ratio file\n",
        "        \"\"\"if control_import_df.equals(divided_data_df):\n",
        "            print(f\"The files match: {new_file_name}\")\n",
        "        else:\n",
        "            print(f\"The files do not match: {new_file_name}\")\"\"\"\n",
        "\n",
        "        #print(control_import_df)\n",
        "        print(divided_data_df)\n",
        "        print(csv_file)\n",
        "        print('****************************************************')\n",
        "    print('===========================================================')"
      ],
      "metadata": {
        "id": "NJwDWCIpsfed",
        "outputId": "4bfdff73-8e7c-449e-f93a-ea1f11e99b4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "divisor_df:        0      1      2             3      4             5      6\n",
            "0  18.59  18.54  18.64  7.451555e+08  100.0  3.443432e+08  100.0\n",
            "data_df:       0      1      2            3      4          5      6\n",
            "0  13.8  13.75  13.86  1480879.721  100.0  661382.63  100.0\n",
            "          0        1         2         3    4         5    6\n",
            "0  0.742335  0.74164  0.743562  0.001987  1.0  0.001921  1.0\n",
            "/content/drive/My Drive/quantitation_output/Sample_177_row1.csv\n",
            "****************************************************\n",
            "divisor_df:        0      1      2             3      4             5      6\n",
            "0  18.59  18.54  18.64  7.451555e+08  100.0  3.443432e+08  100.0\n",
            "data_df:        0      1      2             3      4             5      6\n",
            "0  15.74  15.67  15.82  4.989454e+07  29.99  2.233869e+07  30.75\n",
            "          0       1         2         3       4         5       6\n",
            "0  0.846692  0.8452  0.848712  0.066959  0.2999  0.064873  0.3075\n",
            "/content/drive/My Drive/quantitation_output/Sample_177_row2.csv\n",
            "****************************************************\n",
            "divisor_df:        0      1      2             3      4             5      6\n",
            "0  18.59  18.54  18.64  7.451555e+08  100.0  3.443432e+08  100.0\n",
            "data_df:       0      1      2             3     4            5      6\n",
            "0  20.6  20.56  20.65  2.245815e+07  13.5  9741519.653  13.41\n",
            "          0         1         2         3      4        5       6\n",
            "0  1.108123  1.108954  1.107833  0.030139  0.135  0.02829  0.1341\n",
            "/content/drive/My Drive/quantitation_output/Sample_177_row4.csv\n",
            "****************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-61a18a55ae68>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  divided_data_df = divided_data_df.append(divided_row, ignore_index=True)\n",
            "<ipython-input-6-61a18a55ae68>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  divided_data_df = divided_data_df.append(divided_row, ignore_index=True)\n",
            "<ipython-input-6-61a18a55ae68>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  divided_data_df = divided_data_df.append(divided_row, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "divisor_df:        0      1      2             3      4             5      6\n",
            "0  18.59  18.54  18.64  7.451555e+08  100.0  3.443432e+08  100.0\n",
            "data_df:        0     1      2           3     4           5     6\n",
            "0  25.62  25.6  25.62  974144.385  0.59  778397.485  1.07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-61a18a55ae68>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  divided_data_df = divided_data_df.append(divided_row, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         0         1         2         3       4         5       6\n",
            "0  1.37816  1.380798  1.374464  0.001307  0.0059  0.002261  0.0107\n",
            "/content/drive/My Drive/quantitation_output/Sample_177_row5.csv\n",
            "****************************************************\n",
            "divisor_df:        0      1      2             3      4             5      6\n",
            "0  18.59  18.54  18.64  7.451555e+08  100.0  3.443432e+08  100.0\n",
            "data_df:        0     1      2           3      4             5      6\n",
            "0  26.75  26.7  26.84  92557585.3  55.63  3.900356e+07  53.69\n",
            "          0         1         2         3       4         5       6\n",
            "0  1.438946  1.440129  1.439914  0.124212  0.5563  0.113269  0.5369\n",
            "/content/drive/My Drive/quantitation_output/Sample_177_row6.csv\n",
            "****************************************************\n",
            "divisor_df:        0      1      2             3      4             5      6\n",
            "0  18.59  18.54  18.64  7.451555e+08  100.0  3.443432e+08  100.0\n",
            "data_df:        0      1     2          3     4           5     6\n",
            "0  29.28  29.28  29.3  509975.95  0.31  780206.637  1.07\n",
            "         0         1         2         3       4         5       6\n",
            "0  1.57504  1.579288  1.571888  0.000684  0.0031  0.002266  0.0107\n",
            "/content/drive/My Drive/quantitation_output/Sample_177_row7.csv\n",
            "****************************************************\n",
            "===========================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-61a18a55ae68>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  divided_data_df = divided_data_df.append(divided_row, ignore_index=True)\n",
            "<ipython-input-6-61a18a55ae68>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  divided_data_df = divided_data_df.append(divided_row, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code takes the ratio files as well as the parameters for the linear regression (analyte specific), and yields a final output file that contains all the information, such as the information of the ratio used for the quantitaiton, the parameters for the linear equation as well as other information such as compound id and other general sample information.\n",
        "\n",
        "The final outpur files have the following name format:\n",
        "\n",
        "***Sample_{n}_quantitation_output.csv***\n"
      ],
      "metadata": {
        "id": "8b_QdJRpho9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "current_date = datetime.today().strftime('%Y-%m-%d')\n",
        "output_dir = '/content/drive/My Drive/quantitation_export/'\n",
        "#header_row1 = [f'Analysis Nr. {n}', 'Phthalate concentration calculation', 'Concentration_calibration.ipynb', 'Till Vollmer', current_date]\n",
        "header_row2 = ['Analyte', 'Intercept', 'Slope', 'Value', 'Concentration [microg/ml]']\n",
        "\n",
        "row_descriptors = ['place holder','Dimethylphthalate', 'Diethylphthalate', 'Internal standard', 'Dibutylphthalate', 'Benzylbutylphthalate', 'Bis(2-ethyl-hexyl)phthalate', 'Di-n-octylphthalate']\n",
        "file_pattern = '/content/drive/My Drive/quantitation_output/Sample_{}_row{}_ratio.csv'\n",
        "\n",
        "for n in range(sample_nr_low, sample_nr_high):\n",
        "    output_file = output_dir + f'Sample_{n}_concentration_output_{current_date}.csv'\n",
        "    header_row1 = [f'Analysis Nr. {n}', 'Phthalate concentration calculation', 'Concentration_calibration.ipynb', 'Till Vollmer', current_date]\n",
        "\n",
        "    with open(output_file, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(header_row1)\n",
        "        writer.writerow(header_row2)\n",
        "\n",
        "        for i in range(1, 8):\n",
        "            if i == 3:\n",
        "                continue\n",
        "            print(f'Sample nr: {n}')\n",
        "            print(f'Compound iteration: {i}')\n",
        "            linreg_df = pd.read_csv(f'/content/drive/My Drive/calibration_export/Cal_{i}_analyte_linreg.csv')\n",
        "            print(f'linear function information: {linreg_df}')\n",
        "            descriptor = row_descriptors[i]\n",
        "            print(f'Descriptor: {descriptor}')\n",
        "            file_path = file_pattern.format(n, i)\n",
        "            if not os.path.isfile(file_path):\n",
        "                print(f\"File not found for Sample {n}, Row {i}\")\n",
        "                continue\n",
        "\n",
        "            sample_df = pd.read_csv(file_path, header=None, delimiter=',')\n",
        "            print(f'Sample dataframe: {sample_df}')\n",
        "\n",
        "            # Extracting the slope value from the linear function information\n",
        "            intercept_str = str(linreg_df['Intercept'].values[0])\n",
        "            slope_str = linreg_df['Slope'].values[0]\n",
        "\n",
        "            # Remove the brackets before using regular expressions\n",
        "            slope_str_cleaned = slope_str.strip('[]')\n",
        "            slope_value = ast.literal_eval(slope_str_cleaned)\n",
        "            if isinstance(slope_value, list):\n",
        "                slope_value = slope_value[0]  # If slope is a list, take the first element\n",
        "\n",
        "            intercept = float(re.findall(r'[-\\d.]+', intercept_str)[0])\n",
        "            slope = float(slope_value)\n",
        "\n",
        "            fourth_column = sample_df.iloc[:, 3]  # Accessing the 4th column\n",
        "            value = float(fourth_column.iloc[0])  # Assuming you want the value from the first row (index 0)\n",
        "            concentration = slope * value + intercept\n",
        "            print(f\"Calculated concentration: {concentration}\")\n",
        "            row_data = [descriptor, intercept, slope, value, concentration]\n",
        "            writer.writerow(row_data)\n",
        "\n",
        "            # Additional print statements for debugging\n",
        "            print(f\"Sample DataFrame shape: {sample_df.shape}\")\n",
        "            print(f\"Linreg DataFrame shape: {linreg_df.shape if linreg_df is not None else None}\")\n",
        "            print(\"------------------------------------------------------------------------\")\n",
        "\n"
      ],
      "metadata": {
        "id": "GEJnOOpfr7iv",
        "outputId": "8944fcf1-17c7-4c8e-c2dc-1767bb5f483f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample nr: 177\n",
            "Compound iteration: 1\n",
            "linear function information:    Intercept         Slope  R2 Value\n",
            "0   0.001358  [0.35667912]  0.999713\n",
            "Descriptor: Dimethylphthalate\n",
            "Sample dataframe:           0        1         2         3    4         5    6\n",
            "0  0.742335  0.74164  0.743562  0.001987  1.0  0.001921  1.0\n",
            "Calculated concentration: 0.002066774980712785\n",
            "Sample DataFrame shape: (1, 7)\n",
            "Linreg DataFrame shape: (1, 3)\n",
            "------------------------------------------------------------------------\n",
            "Sample nr: 177\n",
            "Compound iteration: 2\n",
            "linear function information:    Intercept         Slope  R2 Value\n",
            "0   0.001323  [0.38786679]  0.999676\n",
            "Descriptor: Diethylphthalate\n",
            "Sample dataframe:           0       1         2         3       4         5       6\n",
            "0  0.846692  0.8452  0.848712  0.066959  0.2999  0.064873  0.3075\n",
            "Calculated concentration: 0.027294241707773562\n",
            "Sample DataFrame shape: (1, 7)\n",
            "Linreg DataFrame shape: (1, 3)\n",
            "------------------------------------------------------------------------\n",
            "Sample nr: 177\n",
            "Compound iteration: 4\n",
            "linear function information:    Intercept         Slope  R2 Value\n",
            "0   0.002397  [0.65625097]  0.999406\n",
            "Descriptor: Dibutylphthalate\n",
            "Sample dataframe:           0         1         2         3      4        5       6\n",
            "0  1.108123  1.108954  1.107833  0.030139  0.135  0.02829  0.1341\n",
            "Calculated concentration: 0.022175235824509414\n",
            "Sample DataFrame shape: (1, 7)\n",
            "Linreg DataFrame shape: (1, 3)\n",
            "------------------------------------------------------------------------\n",
            "Sample nr: 177\n",
            "Compound iteration: 5\n",
            "linear function information:    Intercept         Slope  R2 Value\n",
            "0  -0.000574  [0.27378756]  0.998631\n",
            "Descriptor: Benzylbutylphthalate\n",
            "Sample dataframe:          0         1         2         3       4         5       6\n",
            "0  1.37816  1.380798  1.374464  0.001307  0.0059  0.002261  0.0107\n",
            "Calculated concentration: -0.00021594878501500486\n",
            "Sample DataFrame shape: (1, 7)\n",
            "Linreg DataFrame shape: (1, 3)\n",
            "------------------------------------------------------------------------\n",
            "Sample nr: 177\n",
            "Compound iteration: 6\n",
            "linear function information:    Intercept        Slope  R2 Value\n",
            "0  -0.001668  [0.4508151]  0.998266\n",
            "Descriptor: Bis(2-ethyl-hexyl)phthalate\n",
            "Sample dataframe:           0         1         2         3       4         5       6\n",
            "0  1.438946  1.440129  1.439914  0.124212  0.5563  0.113269  0.5369\n",
            "Calculated concentration: 0.054329133822228856\n",
            "Sample DataFrame shape: (1, 7)\n",
            "Linreg DataFrame shape: (1, 3)\n",
            "------------------------------------------------------------------------\n",
            "Sample nr: 177\n",
            "Compound iteration: 7\n",
            "linear function information:    Intercept         Slope  R2 Value\n",
            "0  -0.006264  [0.49007004]  0.989461\n",
            "Descriptor: Di-n-octylphthalate\n",
            "Sample dataframe:          0         1         2         3       4         5       6\n",
            "0  1.57504  1.579288  1.571888  0.000684  0.0031  0.002266  0.0107\n",
            "Calculated concentration: -0.005928782426596857\n",
            "Sample DataFrame shape: (1, 7)\n",
            "Linreg DataFrame shape: (1, 3)\n",
            "------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5oggr-01EsQB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}