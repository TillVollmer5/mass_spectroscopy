{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVNO2Rw6z/bAPcTy33uHUz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TillVollmer5/mass_spectroscopy/blob/main/Calibration_calculation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calibration calculation\n",
        "This skript aims to allow the calculation and generation of a linear regression to allow the quantivication of phthalates in the environement.\n",
        "\n",
        "nput: The the peak list files (classic structure, header = 6, by thermofisher) are uploaded to the directory titeled *calibration_input*, it is of key importance that the title of the files follows the format: Cal_\"conc.nr\"_\"series.nr\"_\"identification.nr\"_pl.csv Any changes to filename, path or other changes that might impact the file significantly need to be comented and marked extensively."
      ],
      "metadata": {
        "id": "Z8qnAknfh4gQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code serves to import the librarys and mount the google drive."
      ],
      "metadata": {
        "id": "ZAiV1a2ljKSr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "dqAOn8YyhrnD",
        "outputId": "a449ad10-df28-4a02-a802-fc486122657e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import glob\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import csv\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "\n",
        "# Set path to the folder containing the CSV files\n",
        "path = '/content/drive/My Drive/calibration_input'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This loop aims at importing the various files from the google drive, looping throug the colums and saving them in a new file."
      ],
      "metadata": {
        "id": "60pGfTAYjZtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Outer loop to iterate over the number series\n",
        "for n in range(4, 5):  # Adapted to the number of data sets (number of redundant analyses)\n",
        "    files = glob.glob(f'/content/drive/My Drive/calibration_input/Cal_{n}ug*.csv')\n",
        "    \n",
        "    if not files:\n",
        "        print(f'Files matching pattern \"Cal_{n}ug*.csv\" were not found.')\n",
        "        break\n",
        "    \n",
        "    else:\n",
        "        # Loop over each row and save a separate data frame for each\n",
        "        df = pd.read_csv(files[0], header=4)\n",
        "        num_rows = len(df)\n",
        "        \n",
        "        for i in range(num_rows):\n",
        "            row_dfs = []\n",
        "            for file in files:\n",
        "                # Read in the CSV file\n",
        "                df = pd.read_csv(file, header=4, na_values='')\n",
        "\n",
        "                # Extract the i'th row of the CSV file and append it to the row data frame list\n",
        "                row = df.iloc[i, :].dropna().astype(str)\n",
        "                row_dfs.append(row)\n",
        "\n",
        "            # Concatenate the row data frames along the columns axis and convert to a data frame\n",
        "            combined_df = pd.concat(row_dfs, axis=1).T\n",
        "\n",
        "            # Save the combined data frame to a CSV file with a name indicating the row number\n",
        "            combined_df.to_csv(f'/content/drive/My Drive/calibration_output/Cal_{n}ug_row{i+1}.csv', index=False, header=False)  # Corrected file name formatting and removed headers\n",
        "            \n",
        "            # Convert all values to strings before joining and print the row in the desired format\n",
        "            formatted_row = '\\t'.join(map(str, combined_df.values[0]))\n",
        "            print(formatted_row)\n"
      ],
      "metadata": {
        "id": "lHXFRQ3ns077",
        "outputId": "be959f8e-afd6-4197-b143-fcabb40ce73f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.35\t4.31\t4.39\t65790142350.304\t23.52\t38623269390.338\t25.48\n",
            "6.21\t6.17\t6.23\t22784087462.729\t8.15\t16633771663.194\t10.97\n",
            "7.74\t7.7\t7.77\t31485384232.535\t11.26\t18383070244.296\t12.13\n",
            "13.33\t13.29\t13.4\t43629929619.793\t15.6\t18042749107.326\t11.9\n",
            "18.65\t18.6\t18.69\t33780756994.9\t12.08\t17930008588.157\t11.83\n",
            "20.44\t20.39\t20.54\t39061674749.547\t13.97\t20829965069.204\t13.74\n",
            "22.02\t21.98\t22.23\t43143557380.228\t15.43\t21146814279.364\t13.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following lines use the previously created row file and take the average and the standard deviation *(or the error)* and add them to two new files."
      ],
      "metadata": {
        "id": "JapL2sZXv3AB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ShW_UpfuvE33",
        "outputId": "49f56794-dd1c-4c8c-ab25-fc3e7ba98531",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of all CSV files in the current directory\n",
        "files = glob.glob('/content/drive/My Drive/calibration_output/Cal_*.csv')\n",
        "\n",
        "# Loop over each file\n",
        "for file in files:\n",
        "    # Load the CSV file into a dataframe\n",
        "    df = pd.read_csv(file, header=None)\n",
        "    \n",
        "    # Calculate the mean and standard deviation\n",
        "    df_mean = df.mean(axis=0)\n",
        "    df_mean = df_mean.transpose().to_frame().T\n",
        "    df_std = df.std(axis=0)\n",
        "    df_std = df_std.transpose().to_frame().T\n",
        "\n",
        "    print(df_mean)\n",
        "    print(df_std)\n",
        "    \n",
        "    # Get the file name without the directory path\n",
        "    file_name = os.path.basename(file)\n",
        "    \n",
        "    # Save the mean dataframe to a new CSV file\n",
        "    mean_file_path = '/content/drive/My Drive/calibration_output/' + file_name[:-4] + '_mean.csv'\n",
        "    df_mean.to_csv(mean_file_path, index=False)\n",
        "    \n",
        "    # Save the standard deviation dataframe to a new CSV file\n",
        "    std_file_path = '/content/drive/My Drive/calibration_output/' + file_name[:-4] + '_std.csv'\n",
        "    df_std.to_csv(std_file_path, index=False)\n"
      ],
      "metadata": {
        "id": "3cTOVcyUwM7m",
        "outputId": "acb3fd4f-2ea6-481d-bd89-7b386db469b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        0      1       2             3        4             5        6\n",
            "0  5.0525  5.015  5.1025  8.495416e+10  23.4075  4.227881e+10  22.0775\n",
            "          0         1         2             3         4             5        6\n",
            "0  1.398341  1.396698  1.411698  2.166718e+10  0.379594  8.012253e+09  4.88897\n",
            "      0     1     2             3       4             5       6\n",
            "0  7.31  7.28  7.34  2.609008e+10  7.3675  1.811311e+10  9.4675\n",
            "          0         1         2             3         4             5  \\\n",
            "0  2.193338  2.200015  2.200015  3.577743e+09  0.949469  1.721503e+09   \n",
            "\n",
            "          6  \n",
            "0  1.790054  \n",
            "        0     1     2             3       4             5        6\n",
            "0  8.8825  8.84  8.92  3.922769e+10  10.885  2.512585e+10  12.5425\n",
            "          0     1         2             3         4             5         6\n",
            "0  2.278338  2.28  2.280015  8.644930e+09  0.483908  7.804304e+09  0.639134\n",
            "        0        1      2             3      4             5      6\n",
            "0  14.055  14.0075  14.11  5.681170e+10  15.62  2.792276e+10  13.57\n",
            "          0         1         2             3         4             5  \\\n",
            "0  1.436698  1.441674  1.426674  1.511272e+10  0.333167  1.276926e+10   \n",
            "\n",
            "          6  \n",
            "0  2.848965  \n",
            "         0        1       2             3        4             5        6\n",
            "0  18.9125  18.8575  18.965  4.260406e+10  11.7875  2.416075e+10  12.0725\n",
            "          0         1         2             3         4             5  \\\n",
            "0  0.531688  0.541749  0.523482  9.993886e+09  0.324384  7.396533e+09   \n",
            "\n",
            "          6  \n",
            "0  0.568587  \n",
            "         0        1      2             3        4             5      6\n",
            "0  20.6275  20.5775  20.74  5.430017e+10  14.7725  3.083069e+10  15.14\n",
            "          0         1         2             3         4             5  \\\n",
            "0  0.381696  0.381696  0.366879  1.718541e+10  0.881528  1.164944e+10   \n",
            "\n",
            "          6  \n",
            "0  1.629151  \n",
            "         0        1        2             3       4             5       6\n",
            "0  22.1825  22.1425  22.3375  5.939148e+10  16.165  3.071875e+10  15.135\n",
            "          0         1         2             3       4             5         6\n",
            "0  0.318368  0.311809  0.298147  1.864847e+10  0.9245  1.118831e+10  1.403555\n",
            "         0       1        2             3         4             5         6\n",
            "0  2.52625  3.0075  3.55125  4.247708e+10  13.70375  2.113941e+10  14.03875\n",
            "          0         1         2             3          4             5  \\\n",
            "0  3.572657  2.839034  2.193799  6.007166e+10  13.723175  2.989563e+10   \n",
            "\n",
            "           6  \n",
            "0  11.368509  \n",
            "          0         1         2             3         4             5  \\\n",
            "0  0.699171  1.198349  1.705849  1.083359e+10  2.189797  4.006127e+09   \n",
            "\n",
            "          6  \n",
            "0  5.444485  \n",
            "          0         1         2             3         4             5  \\\n",
            "0  0.988777  0.280508  0.415992  1.532101e+10  2.560014  5.665518e+09   \n",
            "\n",
            "          6  \n",
            "0  0.785617  \n",
            "       0     1     2             3        4             5        6\n",
            "0  3.655  4.14  4.67  1.304504e+10  5.68375  9.056554e+09  7.73375\n",
            "          0         1        2             3         4             5         6\n",
            "0  5.168951  4.440631  3.77595  1.844847e+10  2.381182  1.280790e+10  2.451893\n",
            "          0         1         2             3         4             5  \\\n",
            "0  1.096669  1.600008  2.100008  1.788871e+09  2.474735  8.607517e+08   \n",
            "\n",
            "          6  \n",
            "0  3.895027  \n",
            "          0         1         2             3         4             5  \\\n",
            "0  1.550924  0.848539  0.141432  2.529846e+09  2.157051  1.217287e+09   \n",
            "\n",
            "          6  \n",
            "0  2.976882  \n",
            "         0     1     2             3       4             5        6\n",
            "0  4.44125  4.92  5.46  1.961385e+10  7.4425  1.256293e+10  9.27125\n",
            "          0         1         2             3        4             5         6\n",
            "0  6.280876  5.543717  4.893179  2.773817e+10  4.86843  1.776666e+10  4.626246\n",
            "          0     1         2             3         4             5         6\n",
            "0  1.139169  1.64  2.140007  4.322465e+09  2.241954  3.902152e+09  3.319567\n",
            "          0         1      2             3         4             5         6\n",
            "0  1.611028  0.905097  0.198  6.112888e+09  2.486253  5.518476e+09  3.790705\n",
            "        0        1      2             3     4             5      6\n",
            "0  7.0275  7.50375  8.055  2.840585e+10  9.81  1.396138e+10  9.785\n",
            "          0         1         2             3         4             5  \\\n",
            "0  9.938386  9.197691  8.563063  4.017194e+10  8.216581  1.974438e+10   \n",
            "\n",
            "          6  \n",
            "0  5.352798  \n",
            "          0         1         2             3         4             5  \\\n",
            "0  0.718349  1.220837  1.713337  7.556359e+09  2.166583  6.384631e+09   \n",
            "\n",
            "          6  \n",
            "0  4.424482  \n",
            "          0         1         2             3         4             5  \\\n",
            "0  1.015899  0.312311  0.405402  1.068631e+10  2.592843  9.029232e+09   \n",
            "\n",
            "          6  \n",
            "0  2.228118  \n",
            "         0        1        2             3        4             5        6\n",
            "0  9.45625  9.92875  10.4825  2.130203e+10  7.89375  1.208037e+10  9.03625\n",
            "           0          1          2             3         4             5  \\\n",
            "0  13.373157  12.627159  11.996067  3.012562e+10  5.506594  1.708423e+10   \n",
            "\n",
            "          6  \n",
            "0  4.293906  \n",
            "          0         1         2             3         4             5  \\\n",
            "0  0.265844  0.770874  1.261741  4.996943e+09  2.162192  3.698266e+09   \n",
            "\n",
            "          6  \n",
            "0  3.284294  \n",
            "         0         1         2             3         4             5         6\n",
            "0  0.37596  0.324033  1.044056  7.066744e+09  2.599053  5.230139e+09  3.840589\n",
            "          0         1      2             3        4             5      6\n",
            "0  10.31375  10.78875  11.37  2.715009e+10  9.38625  1.541534e+10  10.57\n",
            "           0          1          2             3         4             5  \\\n",
            "0  14.585845  13.843383  13.251181  3.839602e+10  7.617308  2.180059e+10   \n",
            "\n",
            "          6  \n",
            "0  6.462956  \n",
            "          0         1         2             3         4             5  \\\n",
            "0  0.190848  0.690848  1.183439  8.592704e+09  2.440764  5.824722e+09   \n",
            "\n",
            "          6  \n",
            "0  3.814576  \n",
            "        0         1         2             3         4             5         6\n",
            "0  0.2699  0.437207  1.154791  1.215192e+10  2.205093  8.237400e+09  3.090657\n",
            "          0         1         2             3        4             5        6\n",
            "0  11.09125  11.57125  12.16875  2.969574e+10  10.0825  1.535938e+10  10.5675\n",
            "           0          1          2             3         4             5  \\\n",
            "0  15.685396  14.950005  14.380784  4.199612e+10  8.601954  2.172144e+10   \n",
            "\n",
            "         6  \n",
            "0  6.45942  \n",
            "          0         1         2             3        4             5         6\n",
            "0  0.159184  0.655905  1.149074  9.324233e+09  2.46225  5.594157e+09  3.701778\n",
            "         0         1         2             3         4             5         6\n",
            "0  0.22512  0.486624  1.203392  1.318646e+10  2.174707  7.911332e+09  3.250177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two files contain the internal standard signals are used to take the ratio of the various signals and save the values in a new file. The file needs to be specified so that the internal standard signal correlates to the divisor name, so that this leads to the correct ratio. The first one calculates the ratio of the mean and the bottom one being used for the ratio of the standard deviation, although that might be insuficient and should be substituted by an appropriate error calculation (possibly gaussian errorpropagation)."
      ],
      "metadata": {
        "id": "SbhkIbsFjZW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read divisor value from the divisor file\n",
        "divisor_file = 'divisor.csv'  # Replace with the name of your divisor file\n",
        "\n",
        "with open(divisor_file, 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    divisor = next(reader)[0]  # Assuming the divisor is in the first column\n",
        "\n",
        "# Get a list of CSV files in the directory\n",
        "directory = '/content/drive/My Drive/calibration_output'  # Replace with the actual path to the directory containing the CSV files\n",
        "\n",
        "csv_files = glob.glob(os.path.join(directory, '*_mean.csv'))\n",
        "\n",
        "# Process each CSV file\n",
        "for csv_file in csv_files:\n",
        "    if csv_file == divisor_file:\n",
        "        continue  # Skip the divisor file itself\n",
        "\n",
        "    # Read the contents of the CSV file\n",
        "    with open(csv_file, 'r') as file:\n",
        "        reader = csv.reader(file)\n",
        "        data = list(reader)\n",
        "\n",
        "    # Perform division on the data\n",
        "    divided_data = [[str(float(value) / float(divisor)) for value in row] for row in data]\n",
        "\n",
        "    # Create a new file name with the \"_ratio\" tag\n",
        "    new_file_name = os.path.splitext(csv_file)[0] + '_ratio.csv' #needs to be adapted to fit the final data file name formate\n",
        "\n",
        "    # Write the divided data to the new CSV file\n",
        "     with open(new_file_name, 'w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerows(divided_data)"
      ],
      "metadata": {
        "id": "4ZEmr-SJkcjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read divisor value from the divisor file\n",
        "divisor_file = 'divisor.csv'  # Replace with the name of your divisor file\n",
        "\n",
        "with open(divisor_file, 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    divisor = next(reader)[0]  # Assuming the divisor is in the first column\n",
        "\n",
        "# Get a list of CSV files in the directory\n",
        "directory = '/content/drive/My Drive/calibration_output'  # Replace with the actual path to the directory containing the CSV files\n",
        "\n",
        "csv_files = glob.glob(os.path.join(directory, '*_std.csv'))\n",
        "\n",
        "# Process each CSV file\n",
        "for csv_file in csv_files:\n",
        "    if csv_file == divisor_file:\n",
        "        continue  # Skip the divisor file itself\n",
        "\n",
        "    # Read the contents of the CSV file\n",
        "    with open(csv_file, 'r') as file:\n",
        "        reader = csv.reader(file)\n",
        "        data = list(reader)\n",
        "\n",
        "    # Perform division on the data\n",
        "    divided_data = [[str(float(value) / float(divisor)) for value in row] for row in data]\n",
        "\n",
        "    # Create a new file name with the \"_ratio\" tag\n",
        "    new_file_name = os.path.splitext(csv_file)[0] + '_ratio.csv' #needs to be adapted to fit the final data file name formate\n",
        "\n",
        "    # Write the divided data to the new CSV file\n",
        "     with open(new_file_name, 'w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerows(divided_data)"
      ],
      "metadata": {
        "id": "zajYhAEJk53e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following script creates a plot using the previously optained data. A file containing the concentration will be nescessary to associate the y-axis values with the x-axis values."
      ],
      "metadata": {
        "id": "dBr9ZlOOiqcC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z4RiXPM6jY5t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}