{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3Mi6fp3Z5C7chAVOFMrH5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TillVollmer5/mass_spectroscopy/blob/main/Calibration_calculation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calibration calculation\n",
        "This skript aims to allow the calculation and generation of a linear regression to allow the quantivication of phthalates in the environement.\n",
        "\n",
        "nput: The the peak list files (classic structure, header = 6, by thermofisher) are uploaded to the directory titeled *calibration_input*, it is of key importance that the title of the files follows the format: Cal_\"conc.nr\"_\"series.nr\"_\"identification.nr\"_pl.csv Any changes to filename, path or other changes that might impact the file significantly need to be comented and marked extensively."
      ],
      "metadata": {
        "id": "Z8qnAknfh4gQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code serves to import the librarys and mount the google drive."
      ],
      "metadata": {
        "id": "ZAiV1a2ljKSr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "dqAOn8YyhrnD",
        "outputId": "ae3c0de0-aefc-4f05-abfd-cac6009605dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import glob\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import csv\n",
        "import re\n",
        "\n",
        "drive.mount('/content/drive', force_remount = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This loop aims at importing the various files from the google drive, looping throug the colums and saving them in a new file."
      ],
      "metadata": {
        "id": "60pGfTAYjZtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Outer loop to iterate over the number series related to the concentration\n",
        "for n in range(4, 5):  # Adapted to the number of data sets (number of concentrations)\n",
        "    files = glob.glob(f'/content/drive/My Drive/calibration_input/Cal_{n}ug*.csv')\n",
        "    \n",
        "    if not files:\n",
        "        print(f'Files matching pattern \"Cal_{n}ug*.csv\" were not found.')\n",
        "        break\n",
        "    \n",
        "    else:\n",
        "        # Loop over each row and save a separate data frame for each\n",
        "        df = pd.read_csv(files[0], header=4)\n",
        "        num_rows = len(df)\n",
        "        \n",
        "        for i in range(num_rows):\n",
        "            row_dfs = []\n",
        "            for file in files:\n",
        "                df = pd.read_csv(file, header=4, na_values='')\n",
        "\n",
        "                # Extract the i'th row of the CSV file and append it to the row data frame list\n",
        "                row = df.iloc[i, :].dropna().astype(str)\n",
        "                row_dfs.append(row)\n",
        "\n",
        "            # Concatenate the row data frames along the columns axis and convert to a data frame\n",
        "            combined_df = pd.concat(row_dfs, axis=1).T\n",
        "\n",
        "            # Save the combined data frame to a CSV file with a name indicating the row number\n",
        "            combined_df.to_csv(f'/content/drive/My Drive/calibration_output/Cal_{n}ug_row{i+1}.csv', index=False, header=False)\n",
        "            \n",
        "            # Convert all values to strings before joining and print the row in the desired format\n",
        "            formatted_row = '\\t'.join(map(str, combined_df.values[0]))\n",
        "            print(formatted_row)\n"
      ],
      "metadata": {
        "id": "lHXFRQ3ns077",
        "outputId": "bad76fad-0de6-4a60-a69e-a6f9fcdf33e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.35\t4.31\t4.39\t65790142350.304\t23.52\t38623269390.338\t25.48\n",
            "6.21\t6.17\t6.23\t22784087462.729\t8.15\t16633771663.194\t10.97\n",
            "7.74\t7.7\t7.77\t31485384232.535\t11.26\t18383070244.296\t12.13\n",
            "13.33\t13.29\t13.4\t43629929619.793\t15.6\t18042749107.326\t11.9\n",
            "18.65\t18.6\t18.69\t33780756994.9\t12.08\t17930008588.157\t11.83\n",
            "20.44\t20.39\t20.54\t39061674749.547\t13.97\t20829965069.204\t13.74\n",
            "22.02\t21.98\t22.23\t43143557380.228\t15.43\t21146814279.364\t13.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following lines use the previously created row file and take the average and the standard deviation *(or the error)* and add them to two new files."
      ],
      "metadata": {
        "id": "JapL2sZXv3AB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files = glob.glob('/content/drive/My Drive/calibration_output/Cal_*.csv')\n",
        "\n",
        "# Loop over each file\n",
        "for file in files:\n",
        "    df = pd.read_csv(file, header=None)\n",
        "    \n",
        "    # Calculate the mean and standard deviation\n",
        "    df_mean = df.mean(axis=0)\n",
        "    df_mean = df_mean.transpose().to_frame().T\n",
        "    df_std = df.std(axis=0)\n",
        "    df_std = df_std.transpose().to_frame().T\n",
        "\n",
        "    #print(df_mean)\n",
        "    #print(df_std)\n",
        "    \n",
        "    file_name = os.path.basename(file)\n",
        "    \n",
        "    mean_file_path = '/content/drive/My Drive/calibration_output/' + file_name[:-4] + '_mean.csv'\n",
        "    df_mean.to_csv(mean_file_path, index=False)\n",
        "    \n",
        "    std_file_path = '/content/drive/My Drive/calibration_output/' + file_name[:-4] + '_std.csv'\n",
        "    df_std.to_csv(std_file_path, index=False)\n"
      ],
      "metadata": {
        "id": "3cTOVcyUwM7m"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two files contain the internal standard signals are used to take the ratio of the various signals and save the values in a new file. The file needs to be specified so that the internal standard signal correlates to the divisor name, so that this leads to the correct ratio. The first one calculates the ratio of the mean and the bottom one being used for the ratio of the standard deviation, although that might be insuficient and should be substituted by an appropriate error calculation (possibly gaussian errorpropagation)."
      ],
      "metadata": {
        "id": "SbhkIbsFjZW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "divisor_file = '/content/drive/My Drive/calibration_output/Cal_4ug_row1_mean.csv'\n",
        "directory = '/content/drive/My Drive/calibration_output'\n",
        "\n",
        "divisor_row = pd.read_csv(divisor_file, skiprows=1, header=None)\n",
        "\n",
        "csv_files = glob.glob(os.path.join(directory, '*_mean.csv'))\n",
        "\n",
        "# Process each CSV file\n",
        "for csv_file in csv_files:\n",
        "    if csv_file == divisor_file:\n",
        "        continue  # Skip the divisor file itself\n",
        "\n",
        "    data_df = pd.read_csv(csv_file, skiprows=1, header=None)\n",
        "  \n",
        "    # Perform division on the data\n",
        "    divided_data_df = data_df.div(divisor_row, axis='columns')\n",
        "\n",
        "    # Create a new file name with the \"_ratio\" tag\n",
        "    new_file_name = os.path.splitext(csv_file)[0] + '_ratio.csv'\n",
        "\n",
        "    divided_data_df.to_csv(new_file_name, sep='\\t', header=False, index=False)"
      ],
      "metadata": {
        "id": "uXOB0XUGBSEm"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "divisor_file = '/content/drive/My Drive/calibration_output/Cal_4ug_row1_std.csv'\n",
        "directory = '/content/drive/My Drive/calibration_output'\n",
        "\n",
        "divisor_row = pd.read_csv(divisor_file, skiprows=1, header=None)\n",
        "\n",
        "csv_files = glob.glob(os.path.join(directory, '*_std.csv'))\n",
        "\n",
        "# Process each CSV file\n",
        "for csv_file in csv_files:\n",
        "    if csv_file == divisor_file:\n",
        "        continue  # Skip the divisor file itself\n",
        "\n",
        "    data_df = pd.read_csv(csv_file, skiprows=1, header=None)\n",
        "   \n",
        "\n",
        "    # Perform division on the data\n",
        "    divided_data_df = data_df.div(divisor_row, axis='columns')\n",
        "\n",
        "    # Create a new file name with the \"_ratio\" tag\n",
        "    new_file_name = os.path.splitext(csv_file)[0] + '_ratio.csv'\n",
        "\n",
        "    divided_data_df.to_csv(new_file_name, sep='\\t', header=False, index=False)"
      ],
      "metadata": {
        "id": "SnF2ahk4EAiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following script creates a plot using the previously optained data. A file containing the concentration will be nescessary to associate the y-axis values with the x-axis values."
      ],
      "metadata": {
        "id": "dBr9ZlOOiqcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#does not work, needs to be changed to iterate through the row numbers instead of concentrations...\n",
        "\n",
        "for n in range(4, 5):\n",
        "    # Find the CSV files for the current dataset (based on the value of n)\n",
        "    files = glob.glob(f'/content/drive/My Drive/calibration_output/Cal_{n}ug*_mean_ratio.csv')\n",
        "\n",
        "    # Initialize empty lists for x and y values\n",
        "    x_values = []\n",
        "    y_values = []\n",
        "\n",
        "    x_file = '/content/drive/My Drive/calibration_input/x_values.csv'\n",
        "    x_data = pd.read_csv(x_file, skiprows=1)  # Skip the first row containing the header\n",
        "    x_values = x_data.iloc[:, 0].tolist()  # Access the first column by index\n",
        "\n",
        "    # Read y-axis values from each CSV file\n",
        "    for file in files:\n",
        "        y_data = pd.read_csv(file, header=0)  # Skip the header\n",
        "        y_values.append(y_data.iloc[:, 3].tolist())  # Access the fourth column by index\n",
        "\n",
        "    # Create the plot\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # Plot each y-axis dataset\n",
        "    for y in y_values:\n",
        "        ax.plot(x_values, y)\n",
        "\n",
        "    # Set labels and title\n",
        "    ax.set_xlabel(\"Concentration microg/ml\")\n",
        "    ax.set_ylabel(\"Ratio of analyte to internal standard\")\n",
        "    ax.set_title(\"Calibration\")\n",
        "\n",
        "    # Save the plot as a PDF file\n",
        "    plt.savefig(f\"/content/drive/My Drive/calibration_output/Cal_{n}_analyte_calibration_curve.pdf\")\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Z4RiXPM6jY5t",
        "outputId": "25c586ce-98a5-4add-f508-8aeb2551bd70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-c5cf649e4d06>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0my_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Skip the header\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0my_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Access the fourth column by index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Create the plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1563\u001b[0;31m         \u001b[0mtup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_tuple_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1564\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_tuple_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1464\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1466\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m             \u001b[0;31m# a tuple should already have been caught by this point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1555\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1557\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gSbnbQnUQd9K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}