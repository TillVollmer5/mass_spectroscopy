{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgu6rSVXkCeUSc86bQAsqh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TillVollmer5/mass_spectroscopy/blob/main/Calibration_calculation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calibration calculation\n",
        "This skript aims to allow the calculation and generation of a linear regression to allow the quantivication of phthalates in the environement.\n",
        "\n",
        "nput: The the peak list files (classic structure, header = 6, by thermofisher) are uploaded to the directory titeled *calibration_input*, it is of key importance that the title of the files follows the format: Cal_\"conc.nr\"_\"series.nr\"_\"identification.nr\"_pl.csv Any changes to filename, path or other changes that might impact the file significantly need to be comented and marked extensively."
      ],
      "metadata": {
        "id": "Z8qnAknfh4gQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code serves to import the librarys and mount the google drive."
      ],
      "metadata": {
        "id": "ZAiV1a2ljKSr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "dqAOn8YyhrnD",
        "outputId": "ce6225a9-6fa3-4f60-e8fa-0dfc76d42b56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import glob\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import csv\n",
        "import re\n",
        "\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "\n",
        "#path = '/content/drive/My Drive/calibration_input'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This loop aims at importing the various files from the google drive, looping throug the colums and saving them in a new file."
      ],
      "metadata": {
        "id": "60pGfTAYjZtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Outer loop to iterate over the number series related to the concentration\n",
        "for n in range(4, 5):  # Adapted to the number of data sets (number of concentrations)\n",
        "    files = glob.glob(f'/content/drive/My Drive/calibration_input/Cal_{n}ug*.csv')\n",
        "    \n",
        "    if not files:\n",
        "        print(f'Files matching pattern \"Cal_{n}ug*.csv\" were not found.')\n",
        "        break\n",
        "    \n",
        "    else:\n",
        "        # Loop over each row and save a separate data frame for each\n",
        "        df = pd.read_csv(files[0], header=4)\n",
        "        num_rows = len(df)\n",
        "        \n",
        "        for i in range(num_rows):\n",
        "            row_dfs = []\n",
        "            for file in files:\n",
        "                # Read in the CSV file\n",
        "                df = pd.read_csv(file, header=4, na_values='')\n",
        "\n",
        "                # Extract the i'th row of the CSV file and append it to the row data frame list\n",
        "                row = df.iloc[i, :].dropna().astype(str)\n",
        "                row_dfs.append(row)\n",
        "\n",
        "            # Concatenate the row data frames along the columns axis and convert to a data frame\n",
        "            combined_df = pd.concat(row_dfs, axis=1).T\n",
        "\n",
        "            # Save the combined data frame to a CSV file with a name indicating the row number\n",
        "            combined_df.to_csv(f'/content/drive/My Drive/calibration_output/Cal_{n}ug_row{i+1}.csv', index=False, header=False)\n",
        "            \n",
        "            # Convert all values to strings before joining and print the row in the desired format\n",
        "            formatted_row = '\\t'.join(map(str, combined_df.values[0]))\n",
        "            print(formatted_row)\n"
      ],
      "metadata": {
        "id": "lHXFRQ3ns077",
        "outputId": "0239d0e5-2f50-4a53-e8a2-9fad8ca2a737",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.35\t4.31\t4.39\t65790142350.304\t23.52\t38623269390.338\t25.48\n",
            "6.21\t6.17\t6.23\t22784087462.729\t8.15\t16633771663.194\t10.97\n",
            "7.74\t7.7\t7.77\t31485384232.535\t11.26\t18383070244.296\t12.13\n",
            "13.33\t13.29\t13.4\t43629929619.793\t15.6\t18042749107.326\t11.9\n",
            "18.65\t18.6\t18.69\t33780756994.9\t12.08\t17930008588.157\t11.83\n",
            "20.44\t20.39\t20.54\t39061674749.547\t13.97\t20829965069.204\t13.74\n",
            "22.02\t21.98\t22.23\t43143557380.228\t15.43\t21146814279.364\t13.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following lines use the previously created row file and take the average and the standard deviation *(or the error)* and add them to two new files."
      ],
      "metadata": {
        "id": "JapL2sZXv3AB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files = glob.glob('/content/drive/My Drive/calibration_output/Cal_*.csv')\n",
        "\n",
        "# Loop over each file\n",
        "for file in files:\n",
        "    df = pd.read_csv(file, header=None)\n",
        "    \n",
        "    # Calculate the mean and standard deviation\n",
        "    df_mean = df.mean(axis=0)\n",
        "    df_mean = df_mean.transpose().to_frame().T\n",
        "    df_std = df.std(axis=0)\n",
        "    df_std = df_std.transpose().to_frame().T\n",
        "\n",
        "    print(df_mean)\n",
        "    print(df_std)\n",
        "    \n",
        "    file_name = os.path.basename(file)\n",
        "    \n",
        "    mean_file_path = '/content/drive/My Drive/calibration_output/' + file_name[:-4] + '_mean.csv'\n",
        "    df_mean.to_csv(mean_file_path, index=False)\n",
        "    \n",
        "    std_file_path = '/content/drive/My Drive/calibration_output/' + file_name[:-4] + '_std.csv'\n",
        "    df_std.to_csv(std_file_path, index=False)\n"
      ],
      "metadata": {
        "id": "3cTOVcyUwM7m",
        "outputId": "e69c98aa-a0a2-47a8-b5ce-1fade574ab83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        0      1       2             3        4             5        6\n",
            "0  5.0525  5.015  5.1025  8.495416e+10  23.4075  4.227881e+10  22.0775\n",
            "          0         1         2             3         4             5        6\n",
            "0  1.398341  1.396698  1.411698  2.166718e+10  0.379594  8.012253e+09  4.88897\n",
            "      0     1     2             3       4             5       6\n",
            "0  7.31  7.28  7.34  2.609008e+10  7.3675  1.811311e+10  9.4675\n",
            "          0         1         2             3         4             5  \\\n",
            "0  2.193338  2.200015  2.200015  3.577743e+09  0.949469  1.721503e+09   \n",
            "\n",
            "          6  \n",
            "0  1.790054  \n",
            "        0     1     2             3       4             5        6\n",
            "0  8.8825  8.84  8.92  3.922769e+10  10.885  2.512585e+10  12.5425\n",
            "          0     1         2             3         4             5         6\n",
            "0  2.278338  2.28  2.280015  8.644930e+09  0.483908  7.804304e+09  0.639134\n",
            "        0        1      2             3      4             5      6\n",
            "0  14.055  14.0075  14.11  5.681170e+10  15.62  2.792276e+10  13.57\n",
            "          0         1         2             3         4             5  \\\n",
            "0  1.436698  1.441674  1.426674  1.511272e+10  0.333167  1.276926e+10   \n",
            "\n",
            "          6  \n",
            "0  2.848965  \n",
            "         0        1       2             3        4             5        6\n",
            "0  18.9125  18.8575  18.965  4.260406e+10  11.7875  2.416075e+10  12.0725\n",
            "          0         1         2             3         4             5  \\\n",
            "0  0.531688  0.541749  0.523482  9.993886e+09  0.324384  7.396533e+09   \n",
            "\n",
            "          6  \n",
            "0  0.568587  \n",
            "         0        1      2             3        4             5      6\n",
            "0  20.6275  20.5775  20.74  5.430017e+10  14.7725  3.083069e+10  15.14\n",
            "          0         1         2             3         4             5  \\\n",
            "0  0.381696  0.381696  0.366879  1.718541e+10  0.881528  1.164944e+10   \n",
            "\n",
            "          6  \n",
            "0  1.629151  \n",
            "         0        1        2             3       4             5       6\n",
            "0  22.1825  22.1425  22.3375  5.939148e+10  16.165  3.071875e+10  15.135\n",
            "          0         1         2             3       4             5         6\n",
            "0  0.318368  0.311809  0.298147  1.864847e+10  0.9245  1.118831e+10  1.403555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two files contain the internal standard signals are used to take the ratio of the various signals and save the values in a new file. The file needs to be specified so that the internal standard signal correlates to the divisor name, so that this leads to the correct ratio. The first one calculates the ratio of the mean and the bottom one being used for the ratio of the standard deviation, although that might be insuficient and should be substituted by an appropriate error calculation (possibly gaussian errorpropagation)."
      ],
      "metadata": {
        "id": "SbhkIbsFjZW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "divisor_file = '/content/drive/My Drive/calibration_output/Cal_4ug_row1_mean.csv'\n",
        "directory = '/content/drive/My Drive/calibration_output'\n",
        "\n",
        "divisor_row = pd.read_csv(divisor_file, skiprows=1, header=None)\n",
        "\n",
        "csv_files = glob.glob(os.path.join(directory, '*_mean.csv'))\n",
        "\n",
        "# Process each CSV file\n",
        "for csv_file in csv_files:\n",
        "    if csv_file == divisor_file:\n",
        "        continue  # Skip the divisor file itself\n",
        "\n",
        "    data_df = pd.read_csv(csv_file, skiprows=1, header=None)\n",
        "   \n",
        "\n",
        "    # Perform division on the data\n",
        "    divided_data_df = data_df.div(divisor_row, axis='columns')\n",
        "\n",
        "    # Create a new file name with the \"_ratio\" tag\n",
        "    new_file_name = os.path.splitext(csv_file)[0] + '_ratio.csv'\n",
        "\n",
        "    divided_data_df.to_csv(new_file_name, sep='\\t', header=False, index=False)"
      ],
      "metadata": {
        "id": "uXOB0XUGBSEm"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "divisor_file = '/content/drive/My Drive/calibration_output/Cal_4ug_row1_std.csv'\n",
        "directory = '/content/drive/My Drive/calibration_output'\n",
        "\n",
        "divisor_row = pd.read_csv(divisor_file, skiprows=1, header=None)\n",
        "\n",
        "csv_files = glob.glob(os.path.join(directory, '*_std.csv'))\n",
        "\n",
        "# Process each CSV file\n",
        "for csv_file in csv_files:\n",
        "    if csv_file == divisor_file:\n",
        "        continue  # Skip the divisor file itself\n",
        "\n",
        "    data_df = pd.read_csv(csv_file, skiprows=1, header=None)\n",
        "   \n",
        "\n",
        "    # Perform division on the data\n",
        "    divided_data_df = data_df.div(divisor_row, axis='columns')\n",
        "\n",
        "    # Create a new file name with the \"_ratio\" tag\n",
        "    new_file_name = os.path.splitext(csv_file)[0] + '_ratio.csv'\n",
        "\n",
        "    divided_data_df.to_csv(new_file_name, sep='\\t', header=False, index=False)"
      ],
      "metadata": {
        "id": "SnF2ahk4EAiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following script creates a plot using the previously optained data. A file containing the concentration will be nescessary to associate the y-axis values with the x-axis values."
      ],
      "metadata": {
        "id": "dBr9ZlOOiqcC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z4RiXPM6jY5t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}