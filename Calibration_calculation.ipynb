{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvH48ni2XfZO+A6UMUv+vr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TillVollmer5/mass_spectroscopy/blob/main/Calibration_calculation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calibration calculation\n",
        "This skript aims to allow the calculation and generation of a linear regression to allow the quantivication of phthalates in the environement.\n",
        "\n",
        "nput: The the peak list files (classic structure, header = 6, by thermofisher) are uploaded to the directory titeled *calibration_input*, it is of key importance that the title of the files follows the format: Cal_\"conc.nr\"_\"series.nr\"_\"identification.nr\"_pl.csv Any changes to filename, path or other changes that might impact the file significantly need to be comented and marked extensively."
      ],
      "metadata": {
        "id": "Z8qnAknfh4gQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code serves to import the librarys and mount the google drive."
      ],
      "metadata": {
        "id": "ZAiV1a2ljKSr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dqAOn8YyhrnD",
        "outputId": "61f41a4d-aed3-4627-f8c6-6a9f0fdcef75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import glob\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import csv\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "\n",
        "# Set path to the folder containing the CSV files\n",
        "path = '/content/drive/My Drive/calibration_input'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This loop aims at importing the various files from the google drive, looping throug the colums and saving them in a new file."
      ],
      "metadata": {
        "id": "60pGfTAYjZtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#First version seems rather unoptimized, hence version 2 seems a lot better, select that one if it seems to work.\n",
        "# Get a list of all CSV files in the current directory\n",
        "files = glob.glob('*.csv')\n",
        "\n",
        "# Loop over each CSV file\n",
        "for file in files:\n",
        "    # Read in the CSV file\n",
        "    df = pd.read_csv(file, header = 6)\n",
        "    \n",
        "    # Loop over each row and save a separate data frame for each row\n",
        "    for i, row in df.iterrows():\n",
        "        row_df = pd.DataFrame(row).T\n",
        "        \n",
        "        # Save the row data frame as a new CSV file\n",
        "        row_df.to_csv(f'row{i+1}_{file}', index=False)\n",
        "        \n",
        "# Get a list of all CSV files with row data\n",
        "row_files = glob.glob('row*_file*.csv')\n",
        "\n",
        "# Create an empty list to store the row data frames\n",
        "row_dfs = []\n",
        "\n",
        "# Loop over each row file, read it into a data frame, and append it to the list\n",
        "for file in row_files:\n",
        "    row_df = pd.read_csv(file)\n",
        "    row_dfs.append(row_df)\n",
        "\n",
        "# Concatenate the row data frames along the rows axis\n",
        "combined_df = pd.concat(row_dfs, axis=0)\n",
        "\n",
        "# Save the combined data frame to a CSV file\n",
        "combined_df.to_csv('combined_rows.csv', index=False)\n"
      ],
      "metadata": {
        "id": "_Au8oaF1jzyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#version 2 which seems to be more optimized than version one\n",
        "# Get a list of all CSV files in the current directory\n",
        "files = glob.glob('Cal_*_pl.csv')\n",
        "\n",
        "  # Loop over each row and save a separate data frame for each row\n",
        "  for i in range(len(pd.read_csv(files[0]).columns)):\n",
        "      row_dfs = []\n",
        "      for file in files:\n",
        "          # Read in the CSV file\n",
        "          df = pd.read_csv(file)\n",
        "          \n",
        "          # Extract the i'th row of the CSV file and append it to the row data frame list\n",
        "          row = df.iloc[i]\n",
        "          row_dfs.append(row)\n",
        "          \n",
        "      # Concatenate the row data frames along the columns axis and convert to a data frame\n",
        "      combined_df = pd.concat(row_dfs, axis=1).T\n",
        "      \n",
        "      # Save the combined data frame to a CSV file with a name indicating the row number\n",
        "      combined_df.to_csv('/content/drive/My Drive/calibration_output/row{i+1}.csv', index=False)"
      ],
      "metadata": {
        "id": "MtUS_fl6t-X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "main idea"
      ],
      "metadata": {
        "id": "h_WcVn6HzfTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of all CSV files in the current directory\n",
        "files = glob.glob('Cal_*.csv')\n",
        "\n",
        "# Specify the string prefix and number series in the filename to filter and loop over\n",
        "string_prefix = 'Cal_'\n",
        "number_series = [4]\n",
        "string_suffix = 'ug_ml_*.csv'\n",
        "\n",
        "# Outer loop to iterate over the number series\n",
        "for file_filter in number_series:\n",
        "    filtered_files = [file for file in files if f'{string_prefix}{file_filter}{string_suffix}' in file]\n",
        "\n",
        "    # Loop over each row and save a separate data frame for each \n",
        "    for i in range(len(pd.read_csv(filtered_files[0]).columns)):\n",
        "        row_dfs = []\n",
        "        for file in filtered_files:\n",
        "            # Read in the CSV file\n",
        "            df = pd.read_csv(file)\n",
        "\n",
        "            # Extract the i'th row of the CSV file and append it to the row data frame list\n",
        "            row = df.iloc[i]\n",
        "            row_dfs.append(row)\n",
        "\n",
        "        # Concatenate the row data frames along the columns axis and convert to a data frame\n",
        "        combined_df = pd.concat(row_dfs, axis=1).T\n",
        "\n",
        "        # Save the combined data frame to a CSV file with a name indicating the row number\n",
        "        combined_df.to_csv(f'/content/drive/My Drive/calibration_output/{string_prefix}{file_filter}{string_suffix}_row{i+1}.csv', index=False)\n"
      ],
      "metadata": {
        "id": "Mev7XUSSmf2w",
        "outputId": "eea16d84-21c5-4cea-bbb8-379fa2dd4190",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files: []\n",
            "Filtered Files: []\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-bf79b5c3c382>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Loop over each row and save a separate data frame for each\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mrow_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiltered_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "optimizing/debugging"
      ],
      "metadata": {
        "id": "6djb-1COzhqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "# Get a list of all CSV files in the current directory\n",
        "files = glob.glob('/content/drive/My Drive/calibration_input/Cal_*ug_ml_*.csv')\n",
        "\n",
        "# Check if the files can be opened successfully\n",
        "opened_files = []\n",
        "for file in files:\n",
        "    try:\n",
        "        df = pd.read_csv(file, header=5)\n",
        "        opened_files.append(file)\n",
        "        print(f\"Opened file: {file}\")\n",
        "        print(df.head())  # Display the first few rows of the opened file\n",
        "        print()\n",
        "    except IOError:\n",
        "        print(f\"Error opening file: {file}\")\n",
        "\n",
        "if len(opened_files) == 0:\n",
        "    print(\"No files could be opened. Aborting further processing.\")\n",
        "else:\n",
        "    # Specify the string prefix and number series in the filename to loop over\n",
        "    string_prefix = 'Cal_'\n",
        "    number_list = [4]\n",
        "\n",
        "    # Loop over the number list\n",
        "    for number in number_list:\n",
        "        # Construct the filename pattern based on the string prefix and current number\n",
        "        file_pattern = f'{string_prefix}{number}ug_ml_*.csv'\n",
        "\n",
        "        print(f\"Filtered Files for {number}:\", file_pattern)\n",
        "\n",
        "        # Filter files based on the string prefix and file pattern\n",
        "        filtered_files = [file for file in opened_files if file.endswith(file_pattern)]\n",
        "\n",
        "        if len(filtered_files) == 0:\n",
        "            print(\"No files found for the filter.\")\n",
        "            continue\n",
        "\n",
        "        # Continue with processing the files\n",
        "        for i in range(len(pd.read_csv(filtered_files[0], header=5))):\n",
        "            row_dfs = []\n",
        "            for file in filtered_files:\n",
        "                # Read in the CSV file\n",
        "                df = pd.read_csv(file, header=5)\n",
        "\n",
        "                # Extract the i'th row of the CSV file and append it to the row data frame list\n",
        "                row = df.iloc[i]\n",
        "                row_dfs.append(row)\n",
        "\n",
        "            # Concatenate the row data frames along the columns axis and convert to a data frame\n",
        "            combined_df = pd.concat(row_dfs, axis=1).T\n",
        "\n",
        "            # Save the combined data frame to a CSV file with a name indicating the row number\n",
        "            combined_df.to_csv(f'/content/drive/My Drive/calibration_output/{string_prefix}{number}_row{i+1}.csv', index=False)\n"
      ],
      "metadata": {
        "id": "oE-UKTK6prv1",
        "outputId": "ac60a27e-6f27-4275-c61c-02b6a276acd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opened file: /content/drive/My Drive/calibration_input/Cal_4ug_ml_3.csv\n",
            "    4.35   4.31   4.39  65790142350.304  23.52  38623269390.338  25.48\n",
            "0   6.21   6.17   6.23     2.278409e+10   8.15     1.663377e+10  10.97\n",
            "1   7.74   7.70   7.77     3.148538e+10  11.26     1.838307e+10  12.13\n",
            "2  13.33  13.29  13.40     4.362993e+10  15.60     1.804275e+10  11.90\n",
            "3  18.65  18.60  18.69     3.378076e+10  12.08     1.793001e+10  11.83\n",
            "4  20.44  20.39  20.54     3.906167e+10  13.97     2.082997e+10  13.74\n",
            "\n",
            "Opened file: /content/drive/My Drive/calibration_input/Cal_4ug_ml_4.csv\n",
            "    4.35   4.31   4.39  66717586696.083  23.56  38463262699.681  25.52\n",
            "0   6.21   6.18   6.24     2.326886e+10   8.22     1.665072e+10  11.05\n",
            "1   7.74   7.70   7.78     3.203063e+10  11.31     1.862262e+10  12.36\n",
            "2  13.33  13.28  13.40     4.391215e+10  15.51     1.752313e+10  11.63\n",
            "3  18.64  18.58  18.72     3.412012e+10  12.05     1.783792e+10  11.84\n",
            "4  20.43  20.38  20.57     3.977699e+10  14.05     2.067013e+10  13.72\n",
            "\n",
            "Opened file: /content/drive/My Drive/calibration_input/Cal_4ug_ml_5.csv\n",
            "    4.36   4.33   4.41  101513605015.12  22.85  54283533248.733  22.18\n",
            "0   6.22   6.19   6.25     2.854516e+10   6.43     1.992810e+10   8.14\n",
            "1   7.75   7.70   7.79     4.735730e+10  10.66     2.984678e+10  12.19\n",
            "2  13.35  13.29  13.39     7.141886e+10  16.08     3.182708e+10  13.00\n",
            "3  18.65  18.58  18.70     5.138961e+10  11.57     2.863060e+10  11.70\n",
            "4  20.44  20.39  20.56     6.915619e+10  15.57     4.034618e+10  16.48\n",
            "\n",
            "Opened file: /content/drive/My Drive/calibration_input/Cal_4ug_ml_6.csv\n",
            "    7.15   7.11   7.22  105795286543.679   23.7  37745175837.476  15.13\n",
            "0  10.60  10.58  10.64      2.976220e+10   6.67     1.923984e+10   7.71\n",
            "1  12.30  12.26  12.34      4.603745e+10  10.31     3.365094e+10  13.49\n",
            "2  16.21  16.17  16.25      6.828585e+10  15.29     4.429809e+10  17.75\n",
            "3  19.71  19.67  19.75      5.112576e+10  11.45     3.224445e+10  12.92\n",
            "4  21.20  21.15  21.29      6.920584e+10  15.50     4.147646e+10  16.62\n",
            "\n",
            "Filtered Files for 4: Cal_4ug_ml_*.csv\n",
            "No files found for the filter.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following lines use the previously created row file and take the average and the standard deviation *(or the error)* and add them to two new files."
      ],
      "metadata": {
        "id": "JapL2sZXv3AB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of all CSV files in the current directory\n",
        "files = glob.glob(f'/content/drive/My Drive/calibration_output/cal_*.csv')\n",
        "#Loop over each dataframe\n",
        "\n",
        "for file in files:\n",
        "  #take the mean of the file and save it in a new data frame\n",
        "  df_mean = pd.mean(file)\n",
        "  #save this dataframe in a new csv document\n",
        "  df_mean.to_csv('/content/drive/My Drive/calibration_output/'file'_mean.csv')\n",
        "  #take the standard deviation of the file and save it in a new data frame\n",
        "  df_std = pd.std(file)\n",
        "  #save this dataframe in a new csv document\n",
        "  df_std.to_csv('/content/drive/My Drive/calibration_output/'file'_std.csv')"
      ],
      "metadata": {
        "id": "3cTOVcyUwM7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two files contain the internal standard signals are used to take the ratio of the various signals and save the values in a new file. The file needs to be specified so that the internal standard signal correlates to the divisor name, so that this leads to the correct ratio. The first one calculates the ratio of the mean and the bottom one being used for the ratio of the standard deviation, although that might be insuficient and should be substituted by an appropriate error calculation (possibly gaussian errorpropagation)."
      ],
      "metadata": {
        "id": "SbhkIbsFjZW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read divisor value from the divisor file\n",
        "divisor_file = 'divisor.csv'  # Replace with the name of your divisor file\n",
        "\n",
        "with open(divisor_file, 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    divisor = next(reader)[0]  # Assuming the divisor is in the first column\n",
        "\n",
        "# Get a list of CSV files in the directory\n",
        "directory = '/content/drive/My Drive/calibration_output'  # Replace with the actual path to the directory containing the CSV files\n",
        "\n",
        "csv_files = glob.glob(os.path.join(directory, '*_mean.csv'))\n",
        "\n",
        "# Process each CSV file\n",
        "for csv_file in csv_files:\n",
        "    if csv_file == divisor_file:\n",
        "        continue  # Skip the divisor file itself\n",
        "\n",
        "    # Read the contents of the CSV file\n",
        "    with open(csv_file, 'r') as file:\n",
        "        reader = csv.reader(file)\n",
        "        data = list(reader)\n",
        "\n",
        "    # Perform division on the data\n",
        "    divided_data = [[str(float(value) / float(divisor)) for value in row] for row in data]\n",
        "\n",
        "    # Create a new file name with the \"_ratio\" tag\n",
        "    new_file_name = os.path.splitext(csv_file)[0] + '_ratio.csv' #needs to be adapted to fit the final data file name formate\n",
        "\n",
        "    # Write the divided data to the new CSV file\n",
        "     with open(new_file_name, 'w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerows(divided_data)"
      ],
      "metadata": {
        "id": "4ZEmr-SJkcjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read divisor value from the divisor file\n",
        "divisor_file = 'divisor.csv'  # Replace with the name of your divisor file\n",
        "\n",
        "with open(divisor_file, 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    divisor = next(reader)[0]  # Assuming the divisor is in the first column\n",
        "\n",
        "# Get a list of CSV files in the directory\n",
        "directory = '/content/drive/My Drive/calibration_output'  # Replace with the actual path to the directory containing the CSV files\n",
        "\n",
        "csv_files = glob.glob(os.path.join(directory, '*_std.csv'))\n",
        "\n",
        "# Process each CSV file\n",
        "for csv_file in csv_files:\n",
        "    if csv_file == divisor_file:\n",
        "        continue  # Skip the divisor file itself\n",
        "\n",
        "    # Read the contents of the CSV file\n",
        "    with open(csv_file, 'r') as file:\n",
        "        reader = csv.reader(file)\n",
        "        data = list(reader)\n",
        "\n",
        "    # Perform division on the data\n",
        "    divided_data = [[str(float(value) / float(divisor)) for value in row] for row in data]\n",
        "\n",
        "    # Create a new file name with the \"_ratio\" tag\n",
        "    new_file_name = os.path.splitext(csv_file)[0] + '_ratio.csv' #needs to be adapted to fit the final data file name formate\n",
        "\n",
        "    # Write the divided data to the new CSV file\n",
        "     with open(new_file_name, 'w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerows(divided_data)"
      ],
      "metadata": {
        "id": "zajYhAEJk53e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following script creates a plot using the previously optained data. A file containing the concentration will be nescessary to associate the y-axis values with the x-axis values."
      ],
      "metadata": {
        "id": "dBr9ZlOOiqcC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z4RiXPM6jY5t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}